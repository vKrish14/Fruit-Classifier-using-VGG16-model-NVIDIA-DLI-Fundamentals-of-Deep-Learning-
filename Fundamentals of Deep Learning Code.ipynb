   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "from torchvision import models\n",
    "from torchvision.models import VGG16_Weights\n",
    "import torchvision.io\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Set device with proper CUDA support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"Custom dataset class using torchvision.io.read_image for PNG files\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['freshapples', 'freshbanana', 'freshoranges', \n",
    "                       'rottenapples', 'rottenbanana', 'rottenoranges']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                # Use glob to find PNG files as specified\n",
    "                png_files = glob.glob(os.path.join(class_dir, \"*.png\"))\n",
    "                # Also support other formats as fallback\n",
    "                jpg_files = glob.glob(os.path.join(class_dir, \"*.jpg\"))\n",
    "                jpeg_files = glob.glob(os.path.join(class_dir, \"*.jpeg\"))\n",
    "                \n",
    "                all_files = png_files + jpg_files + jpeg_files\n",
    "                self.images.extend(all_files)\n",
    "                self.labels.extend([self.class_to_idx[class_name]] * len(all_files))\n",
    "        \n",
    "        print(f\"Found {len(self.images)} images in {data_dir}\")\n",
    "        \n",
    "        # Print class distribution\n",
    "        class_counts = {}\n",
    "        for label in self.labels:\n",
    "            class_name = self.classes[label]\n",
    "            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
    "        \n",
    "        for class_name, count in class_counts.items():\n",
    "            print(f\"  {class_name}: {count} images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Use torchvision.io.read_image for better performance\n",
    "            # This returns a tensor in CHW format with values 0-255\n",
    "            image = torchvision.io.read_image(image_path, mode=torchvision.io.ImageReadMode.RGB)\n",
    "            \n",
    "            # Convert to PIL Image for transforms compatibility\n",
    "            image = transforms_v2.functional.to_pil_image(image)\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                \n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a black image as fallback\n",
    "            black_image = torch.zeros(3, 224, 224, dtype=torch.float32)\n",
    "            return black_image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def create_transforms():\n",
    "    \"\"\"Create training and validation transforms using v2 API without deprecated ToTensor\"\"\"\n",
    "    \n",
    "    # Training transforms with augmentation - NO deprecated ToTensor()\n",
    "    train_transforms = transforms_v2.Compose([\n",
    "        transforms_v2.Resize((256, 256)),\n",
    "        transforms_v2.RandomHorizontalFlip(p=0.5),\n",
    "        transforms_v2.RandomRotation(degrees=10),  # As specified: 10 degrees\n",
    "        transforms_v2.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms_v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms_v2.ToImage(),  # Convert to tensor image\n",
    "        transforms_v2.ToDtype(torch.float32, scale=True),  # Scale to [0,1] and convert to float32\n",
    "        transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    # Validation transforms (no augmentation) - NO deprecated ToTensor()\n",
    "    val_transforms = transforms_v2.Compose([\n",
    "        transforms_v2.Resize((224, 224)),\n",
    "        transforms_v2.ToImage(),  # Convert to tensor image\n",
    "        transforms_v2.ToDtype(torch.float32, scale=True),  # Scale to [0,1] and convert to float32\n",
    "        transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    return train_transforms, val_transforms\n",
    "\n",
    "def create_vgg16_model(num_classes=6, freeze_features=True):\n",
    "    \"\"\"Create VGG16 model with custom classifier as specified\"\"\"\n",
    "    \n",
    "    # Load pretrained VGG16 with specified weights\n",
    "    weights = VGG16_Weights.IMAGENET1K_V1\n",
    "    model = models.vgg16(weights=weights)\n",
    "    \n",
    "    # Freeze feature layers if specified\n",
    "    if freeze_features:\n",
    "        for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"VGG16 feature layers frozen for transfer learning\")\n",
    "    else:\n",
    "        print(\" All VGG16 layers unfrozen for fine-tuning\")\n",
    "    \n",
    "    # Replace classifier with custom head as specified:\n",
    "    # Flatten â†’ Dense(4096â†’500) â†’ ReLU â†’ Dense(500â†’6)\n",
    "    # Note: VGG16 already has adaptive pooling, so input to classifier is 25088\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088, 4096),  # VGG16 feature output is 25088\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(4096, 500),    # As specified: 4096 â†’ 500\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(500, num_classes)  # As specified: 500 â†’ 6\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and trainable parameters\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"Model Parameters:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Frozen parameters: {total_params - trainable_params:,}\")\n",
    "    \n",
    "    return total_params, trainable_params\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train model for one epoch with detailed logging\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        # Ensure proper device placement and data types\n",
    "        data = data.to(device, dtype=torch.float32)\n",
    "        target = target.to(device, dtype=torch.long)\n",
    "        \n",
    "        # Verify input shape is correct for VGG16 (batch_size, 3, 224, 224)\n",
    "        assert data.shape[1:] == (3, 224, 224), f\"Expected shape (3, 224, 224), got {data.shape[1:]}\"\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        current_acc = 100. * correct / total\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{current_acc:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate model for one epoch with detailed logging\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "        \n",
    "        for data, target in progress_bar:\n",
    "            # Ensure proper device placement and data types\n",
    "            data = data.to(device, dtype=torch.float32)\n",
    "            target = target.to(device, dtype=torch.long)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_acc = 100. * correct / total\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001):\n",
    "    \"\"\"Complete training pipeline with early stopping\"\"\"\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer as specified\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\" Starting training for {num_epochs} epochs...\")\n",
    "    print(f\" Target validation accuracy: â‰¥92%\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\n Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"Validation accuracy: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        # Detailed epoch logging\n",
    "        print(f'EPOCH {epoch+1} RESULTS:')\n",
    "        print(f'   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'   Val Loss: {val_loss:.4f}   | Val Acc: {val_acc:.2f}%')\n",
    "        print(f'   Best Val Acc: {best_val_acc:.2f}%')\n",
    "        print(f'   Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        \n",
    "        # Check if target accuracy reached\n",
    "        if val_acc >= 92.0:\n",
    "            print(f\"\\nðŸŽ‰ TARGET ACHIEVED! Validation accuracy: {val_acc:.2f}% â‰¥ 92%\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(f\"\\nLoaded best model with validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accs,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "def fine_tune_model(model, train_loader, val_loader, num_epochs=5):\n",
    "    \"\"\"Fine-tune the model by unfreezing all layers with lr=0.0001\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" STARTING FINE-TUNING PHASE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Unfreeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    print(\"All VGG16 layers unfrozen for fine-tuning\")\n",
    "    count_parameters(model)\n",
    "    \n",
    "    # Use smaller learning rate for fine-tuning as specified: lr=0.0001\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nFine-tune Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"Fine-tuned accuracy: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        # Detailed epoch logging\n",
    "        print(f'FINE-TUNE EPOCH {epoch+1} RESULTS:')\n",
    "        print(f'   Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
    "        print(f'   Val Loss: {val_loss:.4f}   | Val Acc: {val_acc:.2f}%')\n",
    "        print(f'   Best Fine-tuned Acc: {best_val_acc:.2f}%')\n",
    "        print(f'   Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        \n",
    "        if val_acc >= 92.0:\n",
    "            print(f\"\\nðŸŽ‰ TARGET MAINTAINED/IMPROVED! Val Acc: {val_acc:.2f}% â‰¥ 92%\")\n",
    "            break\n",
    "    \n",
    "    # Load best fine-tuned model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, best_val_acc\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation metrics\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history['train_losses'], label='Train Loss', marker='o', linewidth=2)\n",
    "    ax1.plot(history['val_losses'], label='Val Loss', marker='s', linewidth=2)\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax2.plot(history['train_accs'], label='Train Acc', marker='o', linewidth=2)\n",
    "    ax2.plot(history['val_accs'], label='Val Acc', marker='s', linewidth=2)\n",
    "    ax2.axhline(y=92, color='r', linestyle='--', linewidth=2, label='Target (92%)')\n",
    "    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    train_dir = os.path.join('data', 'fruits', 'train')\n",
    "    val_dir = os.path.join('data', 'fruits', 'valid')\n",
    "    \n",
    "    # Verify data directories exist\n",
    "    if not os.path.exists(train_dir):\n",
    "        raise FileNotFoundError(f\"Training directory not found: {train_dir}\")\n",
    "    if not os.path.exists(val_dir):\n",
    "        raise FileNotFoundError(f\"Validation directory not found: {val_dir}\")\n",
    "    \n",
    "    print(\"NVIDIA DLI FRUIT CLASSIFICATION ASSIGNMENT\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"device: {device}\")\n",
    "    \n",
    "    # Create transforms without deprecated ToTensor()\n",
    "    train_transforms, val_transforms = create_transforms()\n",
    "    print(\"Data transforms created (v2 API, no deprecated warnings)\")\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"\\nLoading datasets...\")\n",
    "    train_dataset = MyDataset(train_dir, transform=train_transforms)\n",
    "    val_dataset = MyDataset(val_dir, transform=val_transforms)\n",
    "    \n",
    "    print(f\"\\n Dataset Summary:\")\n",
    "    print(f\"   Training samples: {len(train_dataset)}\")\n",
    "    print(f\"   Validation samples: {len(val_dataset)}\")\n",
    "    print(f\"   Classes: {train_dataset.classes}\")\n",
    "    \n",
    "    # Create data loaders with num_workers=0 to avoid shared memory errors\n",
    "    print(\"\\n Creating DataLoaders (num_workers=0 to avoid shared memory errors)...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=32,  # As specified\n",
    "        shuffle=True, \n",
    "        num_workers=0,  # Set to 0 to avoid shared memory errors\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=32,  # As specified\n",
    "        shuffle=False, \n",
    "        num_workers=0,  # Set to 0 to avoid shared memory errors\n",
    "        pin_memory=True if torch.cuda.is_available() else False\n",
    "    )\n",
    "    \n",
    "    print(f\"DataLoaders created (batch_size=32, num_workers=0)\")\n",
    "    \n",
    "    # Create model\n",
    "    print(f\"\\n Creating VGG16 model...\")\n",
    "    model = create_vgg16_model(num_classes=6, freeze_features=True)\n",
    "    \n",
    "    # Count parameters\n",
    "    count_parameters(model)\n",
    "    \n",
    "    # Phase 1: Transfer Learning with frozen features\n",
    "    print(f\"\\n PHASE 1: TRANSFER LEARNING (FROZEN FEATURES)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    my_model, history = train_model(model, train_loader, val_loader, num_epochs=10, learning_rate=0.001)\n",
    "    \n",
    "    print(f\"\\n Phase 1 Results:\")\n",
    "    print(f\"   Best validation accuracy: {history['best_val_acc']:.2f}%\")\n",
    "    \n",
    "    # Phase 2: Fine-tuning if needed\n",
    "    if history['best_val_acc'] < 92.0:\n",
    "        print(f\"\\n Validation accuracy ({history['best_val_acc']:.2f}%) below target.\")\n",
    "        print(\"Starting fine-tuning phase with lr=0.0001...\")\n",
    "        \n",
    "        my_model, final_acc = fine_tune_model(my_model, train_loader, val_loader, num_epochs=5)\n",
    "        \n",
    "        print(f\"\\n Fine-tuning Results:\")\n",
    "        print(f\"   Final validation accuracy: {final_acc:.2f}%\")\n",
    "        \n",
    "        # Update history with fine-tuning results\n",
    "        if final_acc > history['best_val_acc']:\n",
    "            history['best_val_acc'] = final_acc\n",
    "    else:\n",
    "        print(f\"\\n Target accuracy achieved without fine-tuning!\")\n",
    "    \n",
    "    # Plot training history\n",
    "    print(f\"\\n Plotting training history...\")\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(f\"\\n FINAL MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    final_val_loss, final_val_acc = validate_epoch(my_model, val_loader, criterion, device)\n",
    "    \n",
    "    print(f\" Final Results:\")\n",
    "    print(f\"   Final Validation Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"   Final Validation Accuracy: {final_val_acc:.2f}%\")\n",
    "    \n",
    "    if final_val_acc >= 92.0:\n",
    "        print(f\"\\nðŸŽ‰ SUCCESS! Target accuracy of â‰¥92% achieved!\")\n",
    "        print(f\" Model ready for assessment\")\n",
    "    else:\n",
    "        print(f\"\\n  Target accuracy not quite reached.\")\n",
    "        print(f\" Consider more epochs or hyperparameter tuning.\")\n",
    "    \n",
    "    # Save the final model\n",
    "    model_path = 'fruit_classifier_vgg16_final.pth'\n",
    "    torch.save(my_model.state_dict(), model_path)\n",
    "    print(f\"\\n Model saved as '{model_path}'\")\n",
    "    \n",
    "    # Final model summary\n",
    "    print(f\"\\n FINAL MODEL SUMMARY:\")\n",
    "    print(f\"   Architecture: VGG16 + Custom Classifier\")\n",
    "    print(f\"   Input Size: 3 Ã— 224 Ã— 224 (RGB)\")\n",
    "    print(f\"   Output Classes: 6 (fresh/rotten fruits)\")\n",
    "    print(f\"   Final Accuracy: {final_val_acc:.2f}%\")\n",
    "    print(f\"   Transforms: v2 API (no deprecated warnings)\")\n",
    "    print(f\"   DataLoader: num_workers=0 (no shared memory errors)\")\n",
    "    \n",
    "    return my_model\n",
    "\n",
    "# Run the complete training pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Train the model\n",
    "    my_model = main()\n",
    "    \n",
    "    # Final assessment\n",
    "    print(f\"\\n READY FOR FINAL ASSESSMENT!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"To run assessment, uncomment the following lines:\")\n",
    "    print(\"# from run_assessment import run_assessment\")\n",
    "    print(\"# run_assessment(my_model)\")\n",
    "    \n",
    "    # Uncomment these lines when ready for assessment:\n",
    "from run_assessment import run_assessment\n",
    "run_assessment(my_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39139f-145f-4f59-a41e-3a4be2a89cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
